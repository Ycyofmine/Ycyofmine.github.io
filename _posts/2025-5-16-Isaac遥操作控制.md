---
title: Isaac sim遥操作控制
date: 2025-5-16 15:31:23 +0800
categories: [机器人]
tags: [robot] # TAG names should always be lowercase
media_subpath: /assets/img/robot
---
机器人遥操作，这项连接人类智慧与机器行动的技术。从最初简单的远程按钮控制，到如今融合了人工智能（AI）、虚拟现实（VR）、增强现实（AR）的沉浸式、智能化交互，遥操作的应用边界不断拓宽，深入到工业制造、医疗手术、太空探索、灾害救援等众多领域。在这一演进过程中，机器人仿真平台扮演着日益关键的角色。它负责高效地**验证算法**、**加速机器人学习**。

在众多仿真工具中，NVIDIA Isaac Sim 凭借其强大的渲染管线和前瞻性的技术架构，正迅速成为机器人仿真领域，特别是机器人学习中的一颗耀眼新星。接下来笔者将带您深入了解NVIDIA Isaac Sim在遥操作方面的核心能力，并与 Gazebo 和 MuJoCo 这两大仿真平台进行比较。

# NVIDIA Isaac Sim及其强大生态
要理解Isaac Sim在遥操作领域的独特之处，首先需要了解其背后的技术基石：NVIDIA Omniverse平台、OpenUSD标准，以及在此基础上构建的机器人学习框架Isaac Lab。

## 整合多平台与数据格式

![](api-diagram-whiteBG-update25-trim.gif)

NVIDIA Omniverse 是一个基于OpenUSD的可扩展计算平台，专注于构建和运行3D应用程序与服务。它通过整合皮克斯开发的OpenUSD技术，统一复杂的3D工作流程，打破不同工具间的数据壁垒。OpenUSD不仅作为文件格式存在，更是一套强大的场景描述框架，支持多工具实时协作（Blender、Unreal Engine、Houdini）、非破坏性场景编辑以及跨数据源的灵活整合，为3D创作和仿真提供高效互通的解决方案。

![](f8dd2315-4ef0-477f-b8bf-b3b41b63c764.png)

对于机器人仿真和遥操作而言，Omniverse与OpenUSD的结合意义非凡。机器人及其工作环境的模型往往源自不同的建模软件。OpenUSD能够将这些异构数据整合。在遥操作时能感知到更接近真实的环境，对提升操作直觉和决策准确性至关重要。

![](67e93645-3058-4666-beb0-af961deb07ef.png)  

NVIDIA Isaac Sim 是构建在Omniverse平台之上的机器人仿真应用，专为机器人AI的开发、测试和学习而设计。应用自带将 URDF 转换为 USD 的插件，前者是机器人开发中常用的机器人格式

## Isaac Lab加速机器人学习

![](training-teaching-policy-atlas-nvidia-isaac-lab-1.gif)

如果说Isaac Sim提供了高仿真的“世界”，那么Isaac Lab则是赋予机器人“智能”的核心工具 。Isaac Lab是一个构建在Isaac Sim之上的机器人学习框架，它正式取代了之前的Isaac Gym（预览版），并极大地扩展了其功能 。Isaac Lab专注于强化学习（RL）、模仿学习（IL）、运动规划等AI算法的研发，并与Isaac Sim的渲染和场景管理能力更紧密集成。

以下是 NVIDIA Omniverse、Isaac Sim、Isaac Lab 和 Isaac Gym 的关系表格：

| **名称**           | **类型**                     | **基础平台**              | **功能**                                                                 | **状态**       | **备注**                                                                 |
|--------------------|------------------------------|---------------------------|--------------------------------------------------------------------------|----------------|--------------------------------------------------------------------------|
| **NVIDIA Omniverse** | 开发平台/生态系统             | 无（独立平台）            | 提供 API、SDK 和服务，集成 OpenUSD 和 RTX 渲染技术，支持 3D 应用开发       | 当前           | 核心技术：OpenUSD（场景描述框架）、RTX 渲染、PhysX 物理引擎        |
| **Isaac Sim**       | 机器人仿真应用（参考应用）     | NVIDIA Omniverse          | 高保真机器人仿真，支持物理模拟、传感器数据生成、合成数据训练               | 当前           | 基于 PhysX 5 和 OpenUSD，适用于 AI 驱动的机器人开发                |
| **Isaac Lab**       | 机器人学习框架（工具）         | NVIDIA Isaac Sim          | 强化学习（RL）、模仿学习（IL）、运动规划，支持通过遥操作收集人类演示数据    | 当前           | 替代 Isaac Gym，集成 Omniverse 和 Isaac Sim 的功能                |
| **Isaac Gym**       | 机器人学习框架（旧版）         | 独立（预览版）            | GPU 加速物理仿真，用于机器人强化学习和运动控制                             | 已停止支持     | 被 Isaac Lab 取代，功能整合到 Isaac Lab 中                        |

对于遥操作而言，Isaac Lab的一个关键特性是内置通过遥操作等方式收集人类演示数据，这对于机器人学习至关重要。操作员的行为数据可以直接用于训练机器人在Isaac Lab提供的环境中学习复杂任务。

## 类蓝图模式：OmniGraph视觉化脚本
熟悉Unreal Engine的开发者对于其强大的蓝图（Blueprint）可视化脚本系统一定不陌生。在NVIDIA Isaac Sim中，承担类似角色的核心技术是 OmniGraph 。OmniGraph是Omniverse平台通用的可视化编程框架，它允许开发者通过连接不同的功能节点来构建复杂的逻辑和行为，而无需编写大量的传统代码 。   

在Isaac Sim中，OmniGraph扮演着至关重要的角色，它是驱动诸多核心功能的引擎，包括但不限于：

机器人控制：创建和管理机器人控制器，例如差速驱动控制器、关节控制器等 。   
传感器数据处理与发布：连接虚拟传感器，处理其输出数据，并通过ROS/ROS2等方式发布 。   
场景事件响应：根据仿真环境中的事件（如碰撞、时间滴答）触发特定行为 。   
用户界面交互：构建和响应用户界面的输入和事件 。   
合成数据生成（Replicator）：编排和控制合成数据生成流程 。   
OmniGraph的核心理念：

OmniGraph基于节点图的理念，用户可以将代表特定功能或数据的“节点”（Node）拖拽到编辑区，并通过“连接线”（Connection）将它们的输入和输出端口连接起来，从而定义数据流和执行逻辑 。这种可视化的方式极大地降低了编程门槛，使得非程序员也能参与到机器人行为逻辑的设计中，同时也提高了开发效率和可维护性。   

以下是官方提供的教程：

[用OmniGraph控制JetBot](https://docs.isaacsim.omniverse.nvidia.com/latest/omnigraph/omnigraph_tutorial.html)


# Isaac sim遥操作
Isaac Sim不仅提供了基础的远程控制能力，更通过其先进的架构和对新兴技术的支持，为遥操作带来了新的可能性。

## 重定向架构与输入设备

Isaac Sim及其学习框架Isaac Lab中的遥操作，其核心在于一个灵活的“重定向架构”（Retargeting Architecture）。该架构负责将来自各种输入设备的原始信号，通过可配置的重定向器（Retargeters），转换为机器人能够理解的动作指令，例如末端执行器的目标位姿（SE(3)控制）或移动平台的平面速度（SE(2)控制）。

支持的输入设备非常广泛，覆盖了：   
传统设备：键盘（Se2Keyboard, Se3Keyboard）、游戏手柄（如Xbox手柄，通过Se2Gamepad, Se3Gamepad接口）、专业的六自由度SpaceMouse（Se2SpaceMouse, Se3SpaceMouse）。   
前沿XR设备：通过通用的OpenXR设备接口（OpenXRDevice），Isaac Lab能够与符合OpenXR标准的VR/AR头显和控制器配合，利用手部追踪等功能进行直观控制 。特别值得一提的是，通过NVIDIA CloudXR™技术，可以将Isaac Lab的仿真场景以高保真、低延迟的方式流式传输到Apple Vision Pro等高端空间计算设备上，同时将Vision Pro精准的手部追踪数据传回用于控制机器人，提供前所未有的沉浸式遥操作体验。
  
## ROS/ROS2集成
对于广大的机器人开发者而言，与ROS及ROS2的兼容性至关重要。Isaac Sim通过提供ROS/ROS2 Bridge，实现了仿真环境与现有ROS节点、工具和库之间的双向通信。这意味着用户可以将Isaac Sim作为高保真的仿真后端，而将机器人的高级控制逻辑、任务规划、导航算法等保留在熟悉的ROS框架中运行。Isaac Sim支持直接导入URDF和MJCF格式的机器人模型，并支持自定义ROS2消息类型，极大地便利了开发者利用ROS生态进行遥操作应用的构建与调试。需要注意的是，URDF向USD格式转换时，会因格式约束的不同，对关节命名造成改变，具体可以查阅官方文档。

# 主流机器人仿真平台遥操作特性对比
## Gazebo
![](gazebo_diff_drive.png)
Gazebo是一款历史悠久且广泛应用的开源机器人仿真器，以其与ROS/ROS2的深度原生集成而闻名。

- 遥操作优势：对于ROS用户而言，Gazebo的上手门槛较低，可以方便地通过ROS话题和服务进行机器人控制和状态监控。社区提供了海量的开源机器人模型（URDF/SDF）、传感器插件和遥操作包（如teleop_twist_keyboard用于键盘控制 ，joy节点用于手柄控制 ）。它非常适合验证基于ROS的控制算法、导航栈以及基本的遥操作交互逻辑。许多教程和项目展示了如何使用键盘、手柄等设备通过ROS在Gazebo中遥控机器人，包括Atlas人形机器人等复杂系统。
   
- 遥操作局限：Gazebo的渲染效果（主要依赖OGRE 3D）和物理模拟精度（可选ODE、Bullet等，但在复杂接触时可能存在稳定性问题 ）与Isaac Sim相比有明显差距。这可能影响操作员在视觉依赖型或精细物理交互型遥操作任务中的表现和沉浸感。其对AI训练（如大规模合成数据生成）的原生支持也相对薄弱。虽然有研究探索VR/AR和触觉反馈集成，但这通常需要额外开发。

## MuJoCo
![](dmc_grid.png)
MuJoCo（Multi-Joint dynamics with Contact）以其卓越的物理仿真性能（尤其擅长快速准确地处理复杂接触动力学）和轻量级高效的C/Python API著称，在机器人学和强化学习领域备受青睐 。   

- 遥操作优势：MuJoCo的精确物理反馈对于需要理解和学习复杂接触任务（如灵巧手操作 ）的遥操作至关重要。通过其Python API ，开发者可以灵活集成各种输入设备（社区有手柄、VR甚至触觉手套如DOGlove的集成案例 ），并高效收集用于AI训练（特别是RL）的高质量动力学数据。MuJoCo Playground等框架进一步简化了这一过程。
   
- 遥操作局限：MuJoCo内置的可视化功能相对基础，不追求照片级真实感，这可能影响操作员的视觉沉浸体验 。其ROS集成并非原生重点，场景资源和模型库也相对有限，更多依赖用户自建或社区贡献。

## Isaac sim
Isaac Sim凭借NVIDIA Omniverse平台，借助RTX光线追踪技术提供了照片级的真实渲染和基于NVIDIA PhysX的高精度物理仿真（未来还将扩展对MuJoCo等的支持）。

- 遥操作优势：
  1. 高保真度：极致的视觉和物理真实感，让操作员仿佛置身真实场景 。   
  2. OpenUSD原生支持：轻松构建和管理复杂、动态、可组合的仿真世界，为遥操作提供丰富多变的场景 。   
  3. 强大的AI赋能：通过Isaac Lab，深度支持模仿学习和强化学习。遥操作是收集高质量演示数据、训练AI策略的关键一环。Omniverse Replicator可生成大规模合成数据，进一步增强AI模型 。      
  4. ROS良好兼容：通过ROS Bridge与现有ROS项目平滑对接 。   
- 遥操作考量：遥操作系统的高保真特性对硬件资源（尤其是高端NVIDIA GPU）提出了较高要求，其功能复杂性也意味着存在一定的学习门槛。笔者实际使用下来发现，当机器人模型关节数量较多时，易出现CPU负载过高的问题，这主要源于高精度物理仿真与实时渲染的双重资源消耗。

# Newton：全新的仿真平台
Newton是由NVIDIA、Google DeepMind和迪士尼研究院 联合开发的开源物理引擎，专为机器人仿真与学习设计。该引擎基于NVIDIA Warp框架 （一个面向GPU加速的CUDA-X库），通过高度可微性和超实时仿真能力，显著提升了复杂物理交互的计算效率
。其核心目标是解决传统物理引擎在高精度仿真与实时性之间的矛盾，尤其适用于需要大规模数据生成和强化学习的机器人训练场景。

Newton的技术亮点包括：

- GPU加速 ：基于Warp框架，Newton实现了端到端的GPU加速，支持大规模并行仿真。其高度可微的特性使得梯度优化算法（如基于模型的强化学习）能够直接作用于物理模拟过程，从而加速策略学习。

- 跨平台兼容性 ：Newton与主流机器人仿真工具深度整合，包括Google DeepMind的MuJoCo和NVIDIA Isaac Lab，未来或将直接嵌入Isaac Sim的核心物理引擎模块，进一步提升后者的高保真仿真能力。
  
- 超实时操作 ：通过优化计算图结构和内存管理，Newton能够在保持高精度物理模拟的同时，实现超越实时的仿真速度，为大规模训练提供效率保障。

目前，Newton仍处于小范围测试阶段 ，计划于2025年7月正式开源。尽管已有迪士尼研究院等机构参与早期验证，但其在工业级机器人开发中的实际应用案例尚未公开，短期内可能仍需依赖Isaac Sim或MuJoCo等成熟平台完成复杂任务仿真。

# 参考
https://developer.nvidia.com/blog/r2d2-adapting-dexterous-robots-with-nvidia-research-workflows-and-models/

https://isaac-sim.github.io/IsaacLab/main/index.html

https://developer.nvidia.com/isaac/sim

https://fishros.org/doc/ros2/humble/index.html

https://developer.nvidia.com/blog/announcing-newton-an-open-source-physics-engine-for-robotics-simulation/